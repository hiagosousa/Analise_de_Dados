file <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\conjuntoTeste.csv"
dadosTeste <- read.csv(file)
View(dadosTeste)
fileTeste <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\conjuntoTeste.csv"
dadosTeste <- read.csv(fileTeste)
install.packages("tibble")
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("dplyr")
library(dplyr)
library(tidyverse)
library(ggplot2)
library(tibble)
library(readr)
fileTeste <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\conjuntoTeste.csv"
dadosTeste <- read.csv(fileTeste)
fileTreinamento <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\conjuntoTreinamento.csv"
dadosTreinamento <- read.csv(fileTreinamento)
file <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\baseCompleta.csv"
dados <- read.csv(file)
file <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\baseCompleta.csv"
dados <- read.csv(file)
set.seed(123)  # Define a semente para reprodutibilidade dos resultados
k <- 5  # Número de dobras desejado
# Cria um vetor de índices aleatórios
vetorIndicesAleatorios <- sample(1:nrow(dados), replace = FALSE)
# Divide os índices em k grupos
grupos <- cut(vetorIndicesAleatorios, breaks = k, labels = FALSE)
# Inicializa uma lista para armazenar as dobras
dobras <- vector("list", k)
# Preenche cada dobra com os dados estratificados
for (i in 1:k) {
dobras[[i]] <- dados[grupos == i, ]
}
resultados <- vector("list", k)  # Inicializa uma lista para armazenar os resultados
for (i in 1:k) {
# Divide os dados em dados de treinamento e teste para a iteração atual
dadosTreino <- dobras[-i]
dadosTeste <- dobras[[i]]
# Treina o modelo usando os dados de treinamento
modelo <- train(Target ~ ., data = dadosTreino, method = "rf")
# Faz previsões nos dados de teste
predicoes <- predict(modelo, newdata = dadosTeste)
# Calcula as métricas de desempenho para a iteração atual
acuracia <- sum(predicoes == dadosTeste$Target) / nrow(dadosTeste)
# Armazena as métricas na lista de resultados
resultados[[i]] <- acuracia
}
library(caret)
install.packages("caret")
library(caret)
# Treina o modelo usando os dados de treinamento
modelo <- train(Target ~ ., data = dadosTreino, method = "rf")
library(dplyr)
library(tidyverse)
library(ggplot2)
library(tibble)
library(readr)
library(RSNNS)
library(class)
library(tree)
library(caret)
install.packages("tibble")
library(RSNNS)
file <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\baseCompleta.csv"
dados <- read.csv(file)
set.seed(123)  # Define a semente para reprodutibilidade dos resultados
k <- 5  # Número de dobras desejado
# Cria um vetor de índices aleatórios
vetorIndicesAleatorios <- sample(1:nrow(dados), replace = FALSE)
# Divide os índices em k grupos
grupos <- cut(vetorIndicesAleatorios, breaks = k, labels = FALSE)
# Inicializa uma lista para armazenar as dobras
dobras <- vector("list", k)
# Preenche cada dobra com os dados estratificados
for (i in 1:k) {
dobras[[i]] <- dados[grupos == i, ]
}
resultados <- vector("list", k)  # Inicializa uma lista para armazenar os resultados
for (i in 1:k) {
# Divide os dados em dados de treinamento e teste para a iteração atual
dadosTreino <- dobras[-i]
dadosTeste <- dobras[[i]]
# Treina o modelo usando os dados de treinamento
modelo <- train(Target ~ ., data = dadosTreino, method = "rf")
# Faz previsões nos dados de teste
predicoes <- predict(modelo, newdata = dadosTeste)
# Calcula as métricas de desempenho para a iteração atual
acuracia <- sum(predicoes == dadosTeste$Target) / nrow(dadosTeste)
# Armazena as métricas na lista de resultados
resultados[[i]] <- acuracia
}
resultados <- vector("list", k)  # Inicializa uma lista para armazenar os resultados
for (i in 1:k) {
# Divide os dados em dados de treinamento e teste para a iteração atual
dadosTreino <- dobras[-i]
dadosTeste <- dobras[[i]]
# Treina o modelo usando os dados de treinamento
modelo <- train(alvo ~ ., data = dadosTreino, method = "rf")
# Faz previsões nos dados de teste
predicoes <- predict(modelo, newdata = dadosTeste)
# Calcula as métricas de desempenho para a iteração atual
acuracia <- sum(predicoes == dadosTeste$alvo) / nrow(dadosTeste)
# Armazena as métricas na lista de resultados
resultados[[i]] <- acuracia
}
View(dados)
install.packages("RSNNS")
install.packages("class")
install.packages("class")
install.packages("tree")
library(class)
library(tree)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(tibble)
library(readr)
library(RSNNS)
library(class)
library(tree)
library(caret)
file <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\baseCompleta.csv"
dados <- read.csv(file)
View(dados)
# Defina o número de partições
k <- 5
# Embaralhe as linhas do dataframe
set.seed(123)
df_embaralhado <- df[sample(nrow(df)), ]
# Calcule o tamanho de cada partição
tamanho_particao <- ceiling(nrow(df_embaralhado) / k)
df_embaralhado <- dados[sample(nrow(dados)), ]
# Calcule o tamanho de cada partição
tamanho_particao <- ceiling(nrow(df_embaralhado) / k)
# Crie as partições
particoes <- split(df_embaralhado, rep(1:k, each = tamanho_particao, length.out = nrow(df_embaralhado)))
# Acesse as partições individualmente
particao1 <- particoes[[1]]
particao2 <- particoes[[2]]
particao3 <- particoes[[3]]
particao4 <- particoes[[4]]
particao5 <- particoes[[5]]
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes[[2]], particoes[[3]], particoes[[4]], particoes[[5]])
View(particaoTreinamento1)
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes[[2]], particoes[[3]], particoes[[4]], particoes[[5]])
particaoTreinamento2 <- rbind(particoes[[1]], particoes[[3]], particoes[[4]], particoes[[5]])
particaoTreinamento3 <- rbind(particoes[[1]], particoes[[2]], particoes[[4]], particoes[[5]])
particaoTreinamento4 <- rbind(particoes[[1]], particoes[[2]], particoes[[3]], particoes[[5]])
particaoTreinamento5 <- rbind(particoes[[1]], particoes[[2]], particoes[[3]], particoes[[4]])
dados <- read.csv(file)
# Defina o número de partições
k <- 5
# Embaralhe as linhas do dataframe
set.seed(123)
df_embaralhado <- dados[sample(nrow(dados)), ]
# Calcule o tamanho de cada partição
tamanho_particao <- ceiling(nrow(df_embaralhado) / k)
# Crie as partições
particoes <- split(df_embaralhado, rep(1:k, each = tamanho_particao, length.out = nrow(df_embaralhado)))
# Acesse as partições individualmente
particao1 <- particoes[[1]]
particao2 <- particoes[[2]]
particao3 <- particoes[[3]]
particao4 <- particoes[[4]]
particao5 <- particoes[[5]]
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes[[2]], particoes[[3]], particoes[[4]], particoes[[5]])
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes2, particoes3, particoes4, particoes5)
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particao2, particao3, particao4, particao5)
# Acesse as partições individualmente
particao1 <- particoes[[1]]
particao2 <- particoes[[2]]
particao3 <- particoes[[3]]
particao4 <- particoes[[4]]
particao5 <- particoes[[5]]
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particao2, particao3, particao4, particao5)
View(particao1)
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particao2, particao3, particao4, particao5)
cls
clear
particaoTreinamento2 <- rbind(particoes[[1]], particoes[[3]], particoes[[4]], particoes[[5]])
particaoTreinamento3 <- rbind(particoes[[1]], particoes[[2]], particoes[[4]], particoes[[5]])
particaoTreinamento4 <- rbind(particoes[[1]], particoes[[2]], particoes[[3]], particoes[[5]])
particaoTreinamento5 <- rbind(particoes[[1]], particoes[[2]], particoes[[3]], particoes[[4]])
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes[[2]], particoes[[3]], particoes[[4]], particoes[[5]])
cat("\014")
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes[[2]], particoes[[3]], particoes[[4]], particoes[[5]])
particaoTreinamento2 <- rbind(particoes[[1]], particoes[[3]], particoes[[4]], particoes[[5]])
particaoTreinamento3 <- rbind(particoes[[1]], particoes[[2]], particoes[[4]], particoes[[5]])
particaoTreinamento4 <- rbind(particoes[[1]], particoes[[2]], particoes[[3]], particoes[[5]])
particaoTreinamento5 <- rbind(particoes[[1]], particoes[[2]], particoes[[3]], particoes[[4]])
View(particao1)
View(particao2)
View(particao3)
View(particao4)
View(particao5)
#Aqui, realizarei as combinações de treinamento e teste. Fundir as partições 2, 3, 4 e 5 em uma única partição
particaoTreinamento1 <- rbind(particoes[[1]], particoes[[3]], particoes[[4]], particoes[[5]])
View(particaoTreinamento1)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(tibble)
library(readr)
library(RSNNS)
library(class)
library(tree)
library(caret)
file <- "C:\\Users\\hiago\\OneDrive\\Área de Trabalho\\Trabalho 3 IA\\baseCompleta.csv"
dados <- read.csv(file)
# Defina o número de partições
k <- 5
df_embaralhado <- dados[sample(nrow(dados)), ]
# Calcule o tamanho de cada partição
tamanho_particao <- ceiling(nrow(df_embaralhado) / k)
# Crie as partições
particoes <- split(df_embaralhado, rep(1:k, each = tamanho_particao, length.out = nrow(df_embaralhado)))
# Acesse as partições individualmente
particao1 <- particoes[[1]]
particao2 <- particoes[[2]]
particao3 <- particoes[[3]]
particao4 <- particoes[[4]]
particao5 <- particoes[[5]]
